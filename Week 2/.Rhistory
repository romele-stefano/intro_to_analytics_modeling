# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
set.seed(888)
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
kmean.fit <- kmeans(iris[,-5], centers = 3, nstart = 25)
# show cluster
kmean.fit$cluster
par(mfrow=c(1,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
kmean.fit <- kmeans(iris[,-5], centers = 3, nstart = 25)
# show cluster
kmean.fit$cluster
par(mfrow=c(1,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
kmean.fit <- kmeans(iris[,-5], centers = 3, nstart = 25)
# show cluster
kmean.fit$cluster
par(mfrow=c(1,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
set.seed(888)
# BASIC ALGORITHM
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = 3, nstart = 25)
# show cluster
kmean.fit$cluster
par(mfrow=c(1,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
kmean.fit <- kmeans(iris[,-5], centers = 3, nstart = 25)
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
par(mfrow=c(1,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 100)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 100)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 1000)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 10)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(iris[,-5], centers = k, nstart = 10)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
csum = 0
?scale
d_scale <- scale(data)
d_scale <- scale(data[,-5])
kmean.fit <- kmeans(data[,-5], centers = 3, nstart = 25)
# show cluster
kmean.fit$cluster
par(mfrow=c(1,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
kmean.fit <- kmeans(data[,-5], centers = 3, nstart = 25)
# show cluster
kmean.fit$cluster
par(mfrow=c(1,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
kmean.fit <- kmeans(data[,-5], centers = 3, nstart = 25)
# show cluster
kmean.fit$cluster
par(mfrow=c(1,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(data[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(data[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
set.seed(111)
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(data[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
set.seed(111)
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(data[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
set.seed(111)
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(d_scale[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(d_scale[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(d_scale[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(data[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
kmean.fit$centers
kmean.fit <- kmeans(data[,-5], centers = 3, nstart = 25)
kmean.fit$centers
csum = 0
# for each data point...
for (i in 1:nrow(data)) {
# ...add the distance between its point and its cluster center
csum = csum + dist(rbind(data[i,1:4],kmean.fit$centers[kmean.fit$cluster[i],]))
}
cumsum
cumsum[1]
cumsum
table(data[,5], data$Species)
str(data)
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster)
# plot real data
plot(data[c(1,2)], col = data[,5])
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster)
# plot real data
plot(data[c(3,4)], col = data[,5])
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "text")
# plot real data
plot(data[c(1,2)], col = data[,5])
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster)
# plot real data
plot(data[c(3,4)], col = data[,5])
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(1,2)], col = data[,5], main = "Real Data")
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(3,4)], col = data[,5], main = "Real Data")
sum(kmean.fit$cluster == data[,5])/nrow(data)
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
confusion
set.seed(888)
# BASIC ALGORITHM
# kmeans clustering
kmean.fit <- kmeans(data[,-5], centers = 3, nstart = 25)
# show cluster
kmean.fit$cluster
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(1,2)], col = data[,5], main = "Real Data")
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(3,4)], col = data[,5], main = "Real Data")
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
confusion
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- rev(table(kmean.fit$cluster, data[,5]))
confusiomn
confusion
# Iris Setosa = 1, Iris Versicolor = 2, Iris Virginica = 3
confusion <- table(kmean.fit$cluster, data[,5])
# find accuracy
sum(kmean.fit$cluster == data[,5])/nrow(data)
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster", fill=c("blue","red", "green"))
# plot real data
plot(data[c(1,2)], col = data[,5], main = "Real Data")
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(3,4)], col = data[,5], main = "Real Data")
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster", col=c("blue","green","purple"))
# plot real data
plot(data[c(1,2)], col = data[,5], main = "Real Data")
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(3,4)], col = data[,5], main = "Real Data")
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(1,2)], col = data[,5], main = "Real Data")
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(3,4)], col = data[,5], main = "Real Data")
vcol <- c("blue","green","purple")
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster", col=vcol[clus$cluster])
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster", col=vcol[kmean.fit$cluster])
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(1,2)], col = data[,5], main = "Real Data")
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(3,4)], col = data[,5], main = "Real Data")
install.packages("ggplot2")
library(ggplot2)
ggplot(data, aes(x=Sepal.Length, y=Petal.Length, color=Species)) + geom_point()
str(data)
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Petal.Length, color=kmean.fit$cluster)) + geom_point()
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point()
kmean.fit$cluster
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
scale_color_brewer(palette = "Set2")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
discrete_color_brewer(palette = "Set2")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
scale_color_manual(values=c('#999999','#E69F00', '#56B4E9'))
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
scale_color_manual(values=c('#999999','#E69F00', '#56B4E9'))
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
scale_color_gradient(low = "white", high = "red")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
scale_color_gradient(c("red", "blue", "green"))
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point()
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point()+ scale_colour_hue()
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
scale_fill_manual(name = "Values", values=setNames(colors, 1:3))
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point()
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.title = element_blank())
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.title = element_blank())
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
# plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
# plot real data
#plot(data[c(1,2)], col = data[,5], main = "Real Data")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=data[,5])) + geom_point() +
theme(legend.position = "none")
# plot the prediction
#plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
ggplot(data[c(3,4)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
# plot real data
# plot(data[c(3,4)], col = data[,5], main = "Real Data")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=data[,5])) + geom_point() +
theme(legend.position = "none")
str(data)
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
# plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
# plot real data
#plot(data[c(1,2)], col = data[,5], main = "Real Data")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=data[,5])) + geom_point() +
theme(legend.position = "none")
# plot the prediction
#plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
ggplot(data[c(3,4)], aes(x=Petal.Length, y=Petal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
# plot real data
# plot(data[c(3,4)], col = data[,5], main = "Real Data")
ggplot(data[c(1,2)], aes(x=Petal.Length, y=Petal.Width, color=data[,5])) + geom_point() +
theme(legend.position = "none")
str(data)
ggplot(data[c(3,4)], aes(x=Petal.Length, y=Petal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
# plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
# plot real data
#plot(data[c(1,2)], col = data[,5], main = "Real Data")
ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=data[,5])) + geom_point() +
theme(legend.position = "none")
# plot the prediction
#plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
ggplot(data[c(3,4)], aes(x=Petal.Length, y=Petal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
# plot real data
# plot(data[c(3,4)], col = data[,5], main = "Real Data")
ggplot(data[c(3,4)], aes(x=Petal.Length, y=Petal.Width, color=data[,5])) + geom_point() +
theme(legend.position = "none")
p1 <- ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
# plot real data
#plot(data[c(1,2)], col = data[,5], main = "Real Data")
p2 <- ggplot(data[c(1,2)], aes(x=Sepal.Length, y=Sepal.Width, color=data[,5])) + geom_point() +
theme(legend.position = "none")
# plot the prediction
#plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
p3 <- ggplot(data[c(3,4)], aes(x=Petal.Length, y=Petal.Width, color=kmean.fit$cluster)) + geom_point() +
theme(legend.position = "none")
# plot real data
# plot(data[c(3,4)], col = data[,5], main = "Real Data")
p4 <- ggplot(data[c(3,4)], aes(x=Petal.Length, y=Petal.Width, color=data[,5])) + geom_point() +
theme(legend.position = "none")
multiplot(p1, p2, p3, p4, cols=2)
install.packages
install.packages("grid.extra")
install.packages("gridExtra")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, ncol=2)
par(mfrow=c(2,2), mar=c(5,4,2,2))
# plot the prediction
plot(data[c(1,2)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(1,2)], col = data[,5], main = "Real Data")
# plot the prediction
plot(data[c(3,4)], col = kmean.fit$cluster, main = "Cluster")
# plot real data
plot(data[c(3,4)], col = data[,5], main = "Real Data")
set.seed(111)
# automate trying different number of clusters (k)
accuracy <- 0
for (k in 1:5){
# kmeans clustering
kmean.fit <- kmeans(data[,-5], centers = k, nstart = 25)
# find accuracy
accuracy[k] <- sum(kmean.fit$cluster == data[,5])/nrow(data)
}
accuracy
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(data,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(data,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
