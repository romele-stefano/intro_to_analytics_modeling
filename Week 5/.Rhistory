predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
for(i in 1:k){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[k] <- mean(fit_matrix[,k] == data$R1)
}
testIndexes <- which(folds==i,arr.ind=TRUE)
table(validation$R1, predicted)
accuracy <- mean(validation$R1 == predicted)
accuracy
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
accuracy
avg <- sum(accuracy)
avg
avg <- sum(accuracy)/length(accuracy)
avg
data_shuffled <- data[sample(nrow(data)),]
head(data_shuffled)
head(data)
data_shuffled <- data[sample(nrow(data)),]
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
fit_matrix <- matrix(0, nrow = nrow(data), ncol = 10 )
# loop "i" for testing all data -1 data point each time
# loop "j" for testing different values of k each time
for (i in 1:nrow(data)){
for (j in 1:10){
knn.fit = kknn(R1~.,data[-i,],data[i,], k = j, scale = TRUE) # use scaled data
fit_matrix[i,j] <- fitted(knn.fit)
}
}
# transform continuous prediction in binary
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
colnames(fit_matrix) <- c("K=1", "K=2", "K=3", "K=4", "K=5", "K=6", "K=7", "K=8", "K=9", "K=10")
accuracy <- 0
# accuracy with different values of k <- [1] 0.8149847 0.8149847 0.8149847 0.8149847 0.8516820
# 0.8455657 0.8470948 0.8486239 0.8470948 0.8501529
for (k in 1:10){
table(data[,11], fit_matrix[,k])
accuracy[k] <- mean(fit_matrix[,k] == data$R1)
}
accuracy
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
length(predicted)
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
# loop on row of validation for the k-fold
for (j in 1:nrow(validation)){
# loop for testing different values of k neighbor
for (z in 1:10){
knn.fit = kknn(R1~., train, test , k = z, scale = TRUE) # use scaled data
fit_matrix[j,z] <- fitted(knn.fit)
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
correct <- validation$R1 == fit_matrix
answerx[x, 1] = correct
total = sum(answerx)
}
}
}
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
# loop on row of validation for the k-fold
for (j in 1:nrow(validation)){
# loop for testing different values of k neighbor
for (z in 1:10){
knn.fit = kknn(R1~., train, test , k = z, scale = TRUE) # use scaled data
fit_matrix <- fitted(knn.fit)
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
correct <- validation$R1 == fit_matrix
answerx[x, 1] = correct
total = sum(answerx)
}
}
}
length(fit_matrix)
length(validation)
data_shuffled
validation <- data_shuffled[index = 1,]
folds = 1
folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
folds
index <- which(folds = 2)
total
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
answerx <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
# loop on row of validation for the k-fold
for (j in 1:nrow(validation)){
# loop for testing different values of k neighbor
for (z in 1:10){
knn.fit = kknn(R1~., train, test , k = z, scale = TRUE) # use scaled data
fit_matrix <- fitted(knn.fit)
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
correct <- validation$R1 == fit_matrix
answerx[x, 1] = correct
total = sum(answerx)
}
}
}
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
answerx <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
# loop on row of validation for the k-fold
for (j in 1:nrow(validation)){
# loop for testing different values of k neighbor
for (z in 1:10){
knn.fit = kknn(R1~., train, test , k = z, scale = TRUE) # use scaled data
fit_matrix <- fitted(knn.fit)
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
correct <- validation$R1 == fit_matrix
answerx[z, 1] = correct
total = sum(answerx)
}
}
}
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 3, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 7, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
# QUESTION 3.1.B
s <- sample(nrow(data), 0.6*nrow(data))
s
# split data
train <- data[s, ]
test <- data[s*-0.2,]
str(test)
str(train)
test <- data[-s*0.2,]
str(test)
str(train)
test <- data[-s,]
str(test)
test <- data[-train,]
s
test <- data[-s,]
# create a sample with 60% of observation
ss <- sample(1:3, size = nrow(data), prob = c(0.7, 0.15, 0.15), replace = TRUE)
ss
# create a sample with 70% of observation
s <- sample(1:3, size = nrow(data), prob = c(0.7, 0.15, 0.15), replace = TRUE)
s
train <- data[s == 1,]
str(train)
str(data)
0.7*654
train <- data[s == 1,]
train <- data[s == 2,]
train <- data[s == 3,]
s <- sample(1:3, size = nrow(data), prob = c(0.7, 0.15, 0.15), replace = TRUE)
train <- data[s == 1,]
validation <- data[s == 2,]
test <- data[s == 3,]
str(validation)
str(test)
svm.fit <- ksvm(train, validation, type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
svm.fit <- ksvm(as.matrix(train[,1:10]), as.factor(validation[,11]), type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
datamatrix <- as.matrix(data)
head(datamatrix)
svm.fit <- ksvm(datamatrix[,1:10], datamatrix[,11], type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
pred <- predict(svm.fit, data[,1:10])
pred
sum(pred == data[,11]) / nrow(data)
?predict
svm.fit <- ksvm(train, validation, type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
svm.fit <- ksvm(as.matrix(train), as.matrix(validation), type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
svm.fit <- ksvm(as.matrix(train[,1:10]), as.matrix(train[,11]), type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
# predict
pred <- predict(svm.fit, validation)
# predict
pred <- predict(svm.fit, validation[,1:10])
sum(pred == data[,11]) / nrow(data)
sum(pred == validation[,11]) / nrow(data)
?HoltWinters
setwd("C:/Users/ROMEST/Downloads/homework/Week 5")
# for lasso and elastich net
library(glmnet)
data <- read.table("uscrime.txt", header = T)
# create model with all predictors
lm.fit.full <- lm(Crime ~ .,data = data)
m
# create model with only the intercept
lm.fit.initial <- lm(Crime ~ 1, data = data)
# create matrix form
data.scaled = as.matrix(data)
# scale the data
for (i in 1:15) {
#scale predictors
data.scaled[, i] = (data[, i] - min(data[, i])) / (max(data[, i]) - min(data[, i]))
}
# split in predictors and response
predictors <- data.scaled[,1:15]
response <- data.scaled[,16]
# create stepwise
step.fit <- step(lm.fit.initial, scope = list(lower = lm.fit.initial, upper = lm.fit.full), direction = "both")
summary(step.fit)
anova
step.fit$anova
data <- read.table("uscrime.txt", header = T)
# create regression model
lm.fit.stepwise <- lm(Crime ~ Po1+Ineq+Ed+M+Prob+U2, data = data)
summary(lm.fit.stepwise)
# create matrix form
data.scaled = as.matrix(data)
for (i in 1:15) {
#scale predictors
data.scaled[, i] = (data[, i] - min(data[, i])) / (max(data[, i]) - min(data[, i]))
}
# split in predictors and response
predictors <- data.scaled[,1:15]
response <- data.scaled[,16]
# model: lasso
lasso <- glmnet(predictors, response, family = "mgaussian", alpha = 1)
plot(lasso)
summary(lasso)
print(lasso)
# find best lambda value
lasso.fit <- cv.glmnet(predictors, response)
print(lasso.fit)
plot(lasso.fit)
lasso.fit$lambda.min
log(lasso.fit$lambda.min)
log(lasso.fit$lambda.1se)
# find which variables to use
coef(lasso.fit, s = lasso.fit$lambda.min)
str(data)
# regression model for lambda.min
lasso.fit.lambdamin <- lm(Crime ~ M+So+Ed+Po1+LF+M.F+Pop+Nw+U2+Ineq+Prob, data = data)
# regression model for lambda.min
lasso.fit.lambdamin <- lm(Crime ~ M+So+Ed+Po1+LF+M.F+Pop+NW+U2+Ineq+Prob, data = data)
summary(lasso.fit.lambdamin)
coef(lasso.fit, s = lasso.fit$lambda.1se)
# regression model for lambda.1se
lasso.fit.1se <- lm(Crime ~ M+So+Ed+Po1+M.F+NW+U2+Ineq+Prob, data = data)
summary(lasso.fit.1se)
# find best lambda value
lasso.fit <- cv.glmnet(predictors, response, alpha = 1)
plot(lasso.fit)
print(lasso.fit)
# find which variables to use
coef(lasso.fit, s = lasso.fit$lambda.min)
# regression model for lambda.min
lasso.fit.lambdamin <- lm(Crime ~ M+So+Ed+Po1+M.F+NW+U1+U2+Wealth+Ineq+Prob, data = data)
summary(lasso.fit.lambdamin)
?anova.lm
# Remove variables with p-valuer > 0.05
lasso.fit.lambdamin.minimized <- lm(Crime ~ M+So+Po1+U2+Ineq+Prob, data = data)
summary(lasso.fit.lambdamin.minimized)
anova(lasso.fit.lambdamin, lasso.fit.lambdamin.minimized)
# model: ridge regression
elastic <- glmnet(predictors, response, family = "mgaussian", alpha = 0.5)
elastic
plot(elastic)
# find best lambda value
elastic.fit <- cv.glmnet(predictors, response, alpha = 0.5)
plot(elastic.fit)
print(elastic.fit)
# regression model for lambda.1se
lasso.fit.1se <- lm(Crime ~ M+So+Ed+Po1+M.F+NW+U2+Ineq+Prob, data = data)
anova(lasso.fit.lambdamin.minimized, lasso.fit.lambdamin)
# anova between the two models
# https://bookdown.org/ndphillips/YaRrr/comparing-regression-models-with-anova.html
anova(lasso.fit.lambdamin, lasso.fit.lambdamin.minimized)
summary(lasso.fit.1se)
# Remove variables with p-valuer > 0.05
lasso.fit.1se.minimized <- lm(Crime ~ M+Ed+Po1+U2+Ineq+Prob, data = data)
# anova between the two models
# https://bookdown.org/ndphillips/YaRrr/comparing-regression-models-with-anova.html
anova(lasso.fit.1se, lasso.fit.l1se.minimized)
# anova between the two models
# https://bookdown.org/ndphillips/YaRrr/comparing-regression-models-with-anova.html
anova(lasso.fit.1se, lasso.fit.1se.minimized)
elastic.fit
# find which variables to use
coef(elastic.fit, s = elastic.fit$lambda.min)
coef(elastic.fit, s = elastic.fit$lambda.1se)
# find which variables to use
coef(elastic.fit, s = elastic.fit$lambda.min)
# regression model for lambda.min
elastic.fit.lambdamin <- lm(Crime ~ M+So+Ed+Po1+Po2+M.F+Pop+NW+U1+U2+Wealth+Ineq+Prob, data = data)
summary(lasso.elastic.lambdamin)
summary(elastic.fit.lambdamin)
# Remove variables with p-valuer > 0.05
elastic.fit.lambdamin.minimized <- lm(Crime ~ M+Po1+Po2+U2+Ineq+Prob, data = data)
summary(elastic.fit.lambdamin.minimized)
# anova between the two models
# https://bookdown.org/ndphillips/YaRrr/comparing-regression-models-with-anova.html
anova(elastic.fit.lambdamin, elastic.fit.lambdamin.minimized)
anova(elastic.fit.lambdamin.minimized, elastic.fit.lambdamin)
coef(elastic.fit, s = elastic.fit$lambda.1se)
# regression model for lambda.1se
elastic.fit.1se <- lm(Crime ~ M+Po1+Po2+M.F+NW+Ineq+Prob, data = data)
summary(elastic.fit.1se)
# Remove variables with p-valuer > 0.05
elastic.fit.1se.minimized <- lm(Crime ~ M.F+Ineq+Prob, data = data)
summary(elastic.fit.1se.minimized)
# anova between the two models
# https://bookdown.org/ndphillips/YaRrr/comparing-regression-models-with-anova.html
anova(elastic.fit.1se, elastic.fit.1se.minimized)
anova(lasso.fit.lambdamin, elastic.fit.lambdamin)
anova(lasso.fit.lambdamin, lasso.fit.lambdamin.minimized, elastic.fit.lambdamin, elastic.fit.lambdamin.minimized)
install.packages("FrF2")
library(FrF2)
?FrF2
features = c(
"halfacre",
"masteronmain",
"newkitchen",
"GoogleFiber",
"largeclosets",
"historical",
"culdesac",
"openfloorplan",
"goodschools",
"fencedinyard"
)
FrF2(16, factor.names = features)
house.features <- c("sdkad", "jajd")
house.features
set.seed(888)
house.features <- c("large yard", "solar roof", "garage", "pool", "school nearby",
"high speed internet", "guest room", "energy efficient",
"two bathrooms", "cable TV")
FrF2(16, features = house.features)
FrF2(nruns = 16, factor.names = house.features)
# create model with all predictors
lm.fit.full <- lm(Crime ~ .,data = data)
# create model with only the intercept
lm.fit.initial <- lm(Crime ~ 1, data = data)
# create stepwise
step.fit <- step(lm.fit.initial, scope = list(lower = lm.fit.initial, upper = lm.fit.full), direction = "both")
summary(step.fit)
step.fit$anova
anova(lm.fit.stepwise, lasso.fit.lambdamin, elastic.fit.lambdamin)
# compare stepwise, lasso and elastic
anova(lm.fit.stepwise, lasso.fit.lambdamin, lasso.fit.1se, elastic.fit.lambdamin, elastic.fit.1se)
# compare stepwise, lasso and elastic
anova(lm.fit.stepwise, lasso.fit.lambdamin, elastic.fit.lambdamin)
print(elastic.fit)
plot(elastic.fit)
summary(step.fit)
# compare stepwise, lasso and elastic
anova(lm.fit.stepwise, lasso.fit.lambdamin, elastic.fit.lambdamin)
summary(lm.fit.stepwise)
summary(lasso.fit.lambdamin)
summary(elastic.fit.lambdamin)
