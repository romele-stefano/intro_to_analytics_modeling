train <- data[-test,]
test <- data[which(folds == i), ]
str(test)
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
folds
test <- data[which(folds == 2), ]
str(test)
train <- data[-test,]
train <- data[which(folds == -2),]
str(train)
index <- which(folds == 2)
str(index)
train <- data[which(folds == -index),]
train <- data[-index,]
str(train)
?kknn
train$R1
#train the model
knn.fit = kknn(R1~., train, test, k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted
predicted <- ifelse(predicted > 0.5,1,0)
predicted
table(train$R1, predicted)
length(predicted)
nrow(train)
validation <- data[index, ]
index
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
for(i in 1:k){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[k] <- mean(fit_matrix[,k] == data$R1)
}
testIndexes <- which(folds==i,arr.ind=TRUE)
table(validation$R1, predicted)
accuracy <- mean(validation$R1 == predicted)
accuracy
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
accuracy
avg <- sum(accuracy)
avg
avg <- sum(accuracy)/length(accuracy)
avg
data_shuffled <- data[sample(nrow(data)),]
head(data_shuffled)
head(data)
data_shuffled <- data[sample(nrow(data)),]
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
fit_matrix <- matrix(0, nrow = nrow(data), ncol = 10 )
# loop "i" for testing all data -1 data point each time
# loop "j" for testing different values of k each time
for (i in 1:nrow(data)){
for (j in 1:10){
knn.fit = kknn(R1~.,data[-i,],data[i,], k = j, scale = TRUE) # use scaled data
fit_matrix[i,j] <- fitted(knn.fit)
}
}
# transform continuous prediction in binary
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
colnames(fit_matrix) <- c("K=1", "K=2", "K=3", "K=4", "K=5", "K=6", "K=7", "K=8", "K=9", "K=10")
accuracy <- 0
# accuracy with different values of k <- [1] 0.8149847 0.8149847 0.8149847 0.8149847 0.8516820
# 0.8455657 0.8470948 0.8486239 0.8470948 0.8501529
for (k in 1:10){
table(data[,11], fit_matrix[,k])
accuracy[k] <- mean(fit_matrix[,k] == data$R1)
}
accuracy
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
length(predicted)
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
# loop on row of validation for the k-fold
for (j in 1:nrow(validation)){
# loop for testing different values of k neighbor
for (z in 1:10){
knn.fit = kknn(R1~., train, test , k = z, scale = TRUE) # use scaled data
fit_matrix[j,z] <- fitted(knn.fit)
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
correct <- validation$R1 == fit_matrix
answerx[x, 1] = correct
total = sum(answerx)
}
}
}
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
# loop on row of validation for the k-fold
for (j in 1:nrow(validation)){
# loop for testing different values of k neighbor
for (z in 1:10){
knn.fit = kknn(R1~., train, test , k = z, scale = TRUE) # use scaled data
fit_matrix <- fitted(knn.fit)
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
correct <- validation$R1 == fit_matrix
answerx[x, 1] = correct
total = sum(answerx)
}
}
}
length(fit_matrix)
length(validation)
data_shuffled
validation <- data_shuffled[index = 1,]
folds = 1
folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
folds
index <- which(folds = 2)
total
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
answerx <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
# loop on row of validation for the k-fold
for (j in 1:nrow(validation)){
# loop for testing different values of k neighbor
for (z in 1:10){
knn.fit = kknn(R1~., train, test , k = z, scale = TRUE) # use scaled data
fit_matrix <- fitted(knn.fit)
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
correct <- validation$R1 == fit_matrix
answerx[x, 1] = correct
total = sum(answerx)
}
}
}
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
answerx <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data_shuffled)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data_shuffled[-index,]
validation <- data_shuffled[index, ]
# loop on row of validation for the k-fold
for (j in 1:nrow(validation)){
# loop for testing different values of k neighbor
for (z in 1:10){
knn.fit = kknn(R1~., train, test , k = z, scale = TRUE) # use scaled data
fit_matrix <- fitted(knn.fit)
fit_matrix <- ifelse(fit_matrix > 0.5,1,0)
correct <- validation$R1 == fit_matrix
answerx[z, 1] = correct
total = sum(answerx)
}
}
}
data_shuffled <- data[sample(nrow(data)),]
# store the results
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 10, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 3, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
results <- 0
# set number of folds
k_folds <- 10
folds <- cut(seq(1,nrow(data)),breaks = k_folds, labels = FALSE)
for(i in 1:k_folds){
# find index in dataset
index <- which(folds == i)
train <- data[-index,]
validation <- data[index, ]
#train the model
knn.fit = kknn(R1~., train, validation[,-11], k = 7, scale = TRUE) # use scaled data
predicted <- fitted(knn.fit)
predicted <- ifelse(predicted > 0.5,1,0)
table(validation$R1, predicted)
accuracy[i] <- mean(validation$R1 == predicted)
}
avg <- sum(accuracy)/length(accuracy)
avg
# QUESTION 3.1.B
s <- sample(nrow(data), 0.6*nrow(data))
s
# split data
train <- data[s, ]
test <- data[s*-0.2,]
str(test)
str(train)
test <- data[-s*0.2,]
str(test)
str(train)
test <- data[-s,]
str(test)
test <- data[-train,]
s
test <- data[-s,]
# create a sample with 60% of observation
ss <- sample(1:3, size = nrow(data), prob = c(0.7, 0.15, 0.15), replace = TRUE)
ss
# create a sample with 70% of observation
s <- sample(1:3, size = nrow(data), prob = c(0.7, 0.15, 0.15), replace = TRUE)
s
train <- data[s == 1,]
str(train)
str(data)
0.7*654
train <- data[s == 1,]
train <- data[s == 2,]
train <- data[s == 3,]
s <- sample(1:3, size = nrow(data), prob = c(0.7, 0.15, 0.15), replace = TRUE)
train <- data[s == 1,]
validation <- data[s == 2,]
test <- data[s == 3,]
str(validation)
str(test)
svm.fit <- ksvm(train, validation, type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
svm.fit <- ksvm(as.matrix(train[,1:10]), as.factor(validation[,11]), type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
datamatrix <- as.matrix(data)
head(datamatrix)
svm.fit <- ksvm(datamatrix[,1:10], datamatrix[,11], type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
pred <- predict(svm.fit, data[,1:10])
pred
sum(pred == data[,11]) / nrow(data)
?predict
svm.fit <- ksvm(train, validation, type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
svm.fit <- ksvm(as.matrix(train), as.matrix(validation), type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
svm.fit <- ksvm(as.matrix(train[,1:10]), as.matrix(train[,11]), type="C-svc", kernel = "vanilladot", C = 100, scaled = TRUE)
# predict
pred <- predict(svm.fit, validation)
# predict
pred <- predict(svm.fit, validation[,1:10])
sum(pred == data[,11]) / nrow(data)
sum(pred == validation[,11]) / nrow(data)
?HoltWinters
getwd()
setwd("C:/Users/ROMEST/Downloads/homework/Week 5")
dir()
data <- read.table("uscrime.txt", hearder = T)
data <- read.table("uscrime.txt", header = T)
str(data)
?step
?lm
?step
# create model with all predictors
lm.fit.full <- lm(Crime ~ .,data = data)
# create model with one predictors (starting point)
lm.fit.initial <- lm(Crime ~ M, data = data)
# create stepwise
step.fit <- step(lm.fit.initial, scope = lm.fit.full, direction = "both")
summary(step.fit)
# create model with only the intercept
lm.fit.initial <- lm(Crime ~ 1, data = data)
# create stepwise
step.fit <- step(lm.fit.initial, scope = lm.fit.full, direction = "both")
# create stepwise
step.fit <- step(lm.fit.initial, scope = list(lower = lm.fit.initial, upper = lm.fit.full), direction = "both")
summary(step.fit)
names(step.fit)
step.fit$anova
?glmnet
install.packages("glmnet")
# for lasso and elastich net
library(glmnet)
?glmnet
# create matrix form for model
data.matrix <- as.matrix(data)
data.scaled <- scale(data.matrix)
head(data.scaled)
head(data)
str(data.scaled)
predictors <- data.scaled[,1:15]
head(predictors)
response <- data.scaled[,16]
head(response)
head(data.scaled)
# model
glmnet.lasso <- glmn(predictors, response, family = "mgaussian", alpha = 1)
# model
glmnet.lasso <- glmnet(predictors, response, family = "mgaussian", alpha = 1)
summary(glmnet.lasso)
# model
lasso <- glmnet(predictors, response, family = "mgaussian", alpha = 1)
lasso$lambda
lasso$lambda.min
names(lasso)
plot(lasso)
lasso
# model: ridge regression
ridge <- glmnet(predictors, response, family = "mgaussian", alpha = 0)
summary(ridge)
head(ridge)
names(ridge)
ridge.lamba
ridge.lambda
ridge$lambda
lasso
?`stats-package`
library(help = "stats")
coef(lasso)
coef(lasso, s = lasso$lambda)
names(lasso)
lasso$beta
lasso$dev.ratio
length(lasso)
nrow(lasso)
coef(lasso, "lambda.min")
plot(lasso)
plot(ridge)
names(lasso)
plot(lasso$beta)
plot(lasso$beta, label = T)
plot(lasso$beta, label = TRUE)
plot(lasso$beta)
print(lasso)
cvfit = cv.glmnet(predictors, response)
plot(cvfit)
cvfit
cvfit = cv.glmnet(predictors, response)
# find best lambda value
cv.fit <- cv.glmnet(predictors, response)
plot(cv.fit)
cv.fit
?cv.glmnet
coef(cv.fit, s = cv.fit$lambda.min)
cv.fit$lambda.min
cv.fit
# find best lambda value
lasso.fit <- cv.glmnet(predictors, response)
plot(lasso.fit)
coef(lasso.fit, s = lasso.fit$lambda.min)
for (i in 1:15) {
#scale predictors
sc_data[, i] = (data[, i] - min(data[, i])) / (max(data[, i]) - min(data[, i]))
}
sc_data <- 0
for (i in 1:15) {
#scale predictors
sc_data[, i] = (data[, i] - min(data[, i])) / (max(data[, i]) - min(data[, i]))
}
sc_data = as.matrix(data)
for (i in 1:15) {
#scale predictors
sc_data[, i] = (data[, i] - min(data[, i])) / (max(data[, i]) - min(data[, i]))
}
head(sc_data)
head(data.scaled)
data.scaled = as.matrix(data)
for (i in 1:15) {
#scale predictors
data.scaled[, i] = (data[, i] - min(data[, i])) / (max(data[, i]) - min(data[, i]))
}
head(data.scaled)
# split in predictors and response
predictors <- data.scaled[,1:15]
response <- data.scaled[,16]
# find best lambda value
lasso.fit <- cv.glmnet(predictors, response)
plot(lasso.fit)
coef(lasso.fit, s = lasso.fit$lambda.min)
plot(lasso, xvar = "lambda", label = TRUE)
lasso <- glmnet(predictors, response, family = "mgaussian", alpha = 1)
plot(lasso, xvar = "lambda", label = TRUE)
plot(lasso)
# model: lasso
lasso <- glmnet(predictors, response, family = "mgaussian", alpha = 1)
plot(lasso)
plot(lasso.fit)
plot(lasso)
summary(lasso)
summary(lasso.fit)
coef(lasso.fit, s = lasso.fit$lambda.lse)
names(lasso.fit)
coef(lasso.fit, s = lasso.fit$lambda.1se)
plot(lasso.fit)
print(lasso.fit)
